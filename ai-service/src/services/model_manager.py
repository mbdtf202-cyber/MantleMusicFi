"""
æ¨¡å‹ç®¡ç†å™¨
è´Ÿè´£åŠ è½½ã€ç®¡ç†å’Œä¼˜åŒ–AIæ¨¡å‹
"""

import os
import logging
import asyncio
import psutil
from typing import Dict, List, Optional, Any
from pathlib import Path
import torch
import numpy as np
from transformers import AutoModel, AutoTokenizer, pipeline
import librosa
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

logger = logging.getLogger(__name__)

class ModelManager:
    """AIæ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self):
        self.initialized = False
        self.models = {}
        self.tokenizers = {}
        self.pipelines = {}
        self.feature_extractors = {}
        self.device = self._get_device()
        self.model_cache_dir = Path(os.getenv("MODEL_CACHE_DIR", "./models"))
        self.model_cache_dir.mkdir(exist_ok=True)
        
    def _get_device(self) -> str:
        """è·å–è®¡ç®—è®¾å¤‡"""
        if torch.cuda.is_available():
            return "cuda"
        elif torch.backends.mps.is_available():
            return "mps"
        else:
            return "cpu"
    
    async def initialize(self):
        """åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨"""
        try:
            logger.info(f"ğŸ”§ åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨ï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
            
            # åˆ›å»ºæ¨¡å‹ç›®å½•
            self.model_cache_dir.mkdir(exist_ok=True)
            
            # åˆå§‹åŒ–åŸºç¡€ç»„ä»¶
            await self._initialize_audio_models()
            await self._initialize_text_models()
            await self._initialize_recommendation_models()
            
            self.initialized = True
            logger.info("âœ… æ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def _initialize_audio_models(self):
        """åˆå§‹åŒ–éŸ³é¢‘åˆ†ææ¨¡å‹"""
        try:
            # éŸ³é¢‘ç‰¹å¾æå–å™¨
            self.feature_extractors['audio'] = {
                'sample_rate': 22050,
                'n_mels': 128,
                'n_fft': 2048,
                'hop_length': 512
            }
            
            # éŸ³ä¹æµæ´¾åˆ†ç±»æ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            self.models['genre_classifier'] = self._create_simple_genre_classifier()
            
            # éŸ³é¢‘ç›¸ä¼¼åº¦è®¡ç®—å™¨
            self.models['audio_similarity'] = self._create_audio_similarity_model()
            
            logger.info("âœ… éŸ³é¢‘æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def _initialize_text_models(self):
        """åˆå§‹åŒ–æ–‡æœ¬åˆ†ææ¨¡å‹"""
        try:
            # æƒ…æ„Ÿåˆ†æç®¡é“ï¼ˆä½¿ç”¨è½»é‡çº§æ¨¡å‹ï¼‰
            try:
                self.pipelines['sentiment'] = pipeline(
                    "sentiment-analysis",
                    model="cardiffnlp/twitter-roberta-base-sentiment-latest",
                    device=0 if self.device == "cuda" else -1
                )
            except Exception:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ç®€å•çš„æƒ…æ„Ÿåˆ†æ
                self.pipelines['sentiment'] = self._create_simple_sentiment_analyzer()
            
            # æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—å™¨
            self.models['text_similarity'] = TfidfVectorizer(
                max_features=5000,
                stop_words='english',
                ngram_range=(1, 2)
            )
            
            logger.info("âœ… æ–‡æœ¬æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ–‡æœ¬æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def _initialize_recommendation_models(self):
        """åˆå§‹åŒ–æ¨èæ¨¡å‹"""
        try:
            # ååŒè¿‡æ»¤æ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            self.models['collaborative_filter'] = self._create_collaborative_filter()
            
            # å†…å®¹æ¨èæ¨¡å‹
            self.models['content_recommender'] = self._create_content_recommender()
            
            # æ··åˆæ¨èæ¨¡å‹
            self.models['hybrid_recommender'] = self._create_hybrid_recommender()
            
            logger.info("âœ… æ¨èæ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ¨èæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _create_simple_genre_classifier(self):
        """åˆ›å»ºç®€å•çš„éŸ³ä¹æµæ´¾åˆ†ç±»å™¨"""
        class SimpleGenreClassifier:
            def __init__(self):
                self.genres = ['pop', 'rock', 'jazz', 'classical', 'electronic', 'hip-hop']
            
            def predict(self, audio_features):
                """åŸºäºéŸ³é¢‘ç‰¹å¾é¢„æµ‹æµæ´¾"""
                # ç®€åŒ–çš„æµæ´¾åˆ†ç±»é€»è¾‘
                if audio_features.get('tempo', 120) > 140:
                    return 'electronic' if audio_features.get('energy', 0.5) > 0.7 else 'pop'
                elif audio_features.get('tempo', 120) < 80:
                    return 'classical' if audio_features.get('acousticness', 0.5) > 0.7 else 'jazz'
                else:
                    return 'rock' if audio_features.get('energy', 0.5) > 0.6 else 'pop'
        
        return SimpleGenreClassifier()
    
    def _create_audio_similarity_model(self):
        """åˆ›å»ºéŸ³é¢‘ç›¸ä¼¼åº¦æ¨¡å‹"""
        class AudioSimilarityModel:
            def compute_similarity(self, features1, features2):
                """è®¡ç®—ä¸¤ä¸ªéŸ³é¢‘ç‰¹å¾çš„ç›¸ä¼¼åº¦"""
                # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
                f1 = np.array(list(features1.values()))
                f2 = np.array(list(features2.values()))
                
                # å½’ä¸€åŒ–
                f1_norm = f1 / np.linalg.norm(f1)
                f2_norm = f2 / np.linalg.norm(f2)
                
                # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                similarity = np.dot(f1_norm, f2_norm)
                return float(similarity)
        
        return AudioSimilarityModel()
    
    def _create_simple_sentiment_analyzer(self):
        """åˆ›å»ºç®€å•çš„æƒ…æ„Ÿåˆ†æå™¨"""
        class SimpleSentimentAnalyzer:
            def __init__(self):
                # ç®€å•çš„æƒ…æ„Ÿè¯å…¸
                self.positive_words = {'love', 'happy', 'joy', 'amazing', 'wonderful', 'great', 'beautiful'}
                self.negative_words = {'hate', 'sad', 'angry', 'terrible', 'awful', 'bad', 'horrible'}
            
            def __call__(self, text):
                words = text.lower().split()
                positive_count = sum(1 for word in words if word in self.positive_words)
                negative_count = sum(1 for word in words if word in self.negative_words)
                
                if positive_count > negative_count:
                    return [{'label': 'POSITIVE', 'score': 0.7}]
                elif negative_count > positive_count:
                    return [{'label': 'NEGATIVE', 'score': 0.7}]
                else:
                    return [{'label': 'NEUTRAL', 'score': 0.5}]
        
        return SimpleSentimentAnalyzer()
    
    def _create_collaborative_filter(self):
        """åˆ›å»ºååŒè¿‡æ»¤æ¨¡å‹"""
        class CollaborativeFilter:
            def __init__(self):
                self.user_item_matrix = None
                self.similarity_matrix = None
            
            def fit(self, user_item_data):
                """è®­ç»ƒååŒè¿‡æ»¤æ¨¡å‹"""
                # ç®€åŒ–çš„ååŒè¿‡æ»¤å®ç°
                self.user_item_matrix = user_item_data
                # è®¡ç®—ç”¨æˆ·ç›¸ä¼¼åº¦çŸ©é˜µ
                self.similarity_matrix = cosine_similarity(user_item_data)
            
            def recommend(self, user_id, n_recommendations=10):
                """ä¸ºç”¨æˆ·æ¨èéŸ³ä¹"""
                if self.user_item_matrix is None:
                    return []
                
                # ç®€åŒ–çš„æ¨èé€»è¾‘
                similar_users = self.similarity_matrix[user_id].argsort()[-10:][::-1]
                recommendations = []
                
                for similar_user in similar_users:
                    if similar_user != user_id:
                        # è·å–ç›¸ä¼¼ç”¨æˆ·å–œæ¬¢çš„éŸ³ä¹
                        user_items = self.user_item_matrix[similar_user]
                        recommendations.extend(user_items.nonzero()[0])
                
                return list(set(recommendations))[:n_recommendations]
        
        return CollaborativeFilter()
    
    def _create_content_recommender(self):
        """åˆ›å»ºå†…å®¹æ¨èæ¨¡å‹"""
        class ContentRecommender:
            def __init__(self):
                self.feature_matrix = None
                self.similarity_matrix = None
            
            def fit(self, music_features):
                """è®­ç»ƒå†…å®¹æ¨èæ¨¡å‹"""
                self.feature_matrix = music_features
                self.similarity_matrix = cosine_similarity(music_features)
            
            def recommend(self, music_id, n_recommendations=10):
                """åŸºäºéŸ³ä¹å†…å®¹æ¨èç›¸ä¼¼éŸ³ä¹"""
                if self.similarity_matrix is None:
                    return []
                
                similarities = self.similarity_matrix[music_id]
                similar_indices = similarities.argsort()[-n_recommendations-1:-1][::-1]
                
                return similar_indices.tolist()
        
        return ContentRecommender()
    
    def _create_hybrid_recommender(self):
        """åˆ›å»ºæ··åˆæ¨èæ¨¡å‹"""
        class HybridRecommender:
            def __init__(self, collaborative_filter, content_recommender):
                self.collaborative_filter = collaborative_filter
                self.content_recommender = content_recommender
                self.cf_weight = 0.6
                self.content_weight = 0.4
            
            def recommend(self, user_id, music_id=None, n_recommendations=10):
                """æ··åˆæ¨è"""
                recommendations = []
                
                # ååŒè¿‡æ»¤æ¨è
                cf_recs = self.collaborative_filter.recommend(user_id, n_recommendations)
                recommendations.extend([(rec, self.cf_weight) for rec in cf_recs])
                
                # å†…å®¹æ¨è
                if music_id is not None:
                    content_recs = self.content_recommender.recommend(music_id, n_recommendations)
                    recommendations.extend([(rec, self.content_weight) for rec in content_recs])
                
                # åˆå¹¶å’Œæ’åº
                rec_scores = {}
                for rec, weight in recommendations:
                    rec_scores[rec] = rec_scores.get(rec, 0) + weight
                
                sorted_recs = sorted(rec_scores.items(), key=lambda x: x[1], reverse=True)
                return [rec for rec, score in sorted_recs[:n_recommendations]]
        
        return HybridRecommender(
            self.models.get('collaborative_filter'),
            self.models.get('content_recommender')
        )
    
    async def preload_models(self):
        """é¢„åŠ è½½æ ¸å¿ƒæ¨¡å‹"""
        try:
            logger.info("ğŸ”„ é¢„åŠ è½½æ ¸å¿ƒæ¨¡å‹...")
            
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ¨¡å‹é¢„çƒ­é€»è¾‘
            # ä¾‹å¦‚ï¼šè¿è¡Œä¸€äº›ç¤ºä¾‹æ¨ç†æ¥åˆå§‹åŒ–æ¨¡å‹
            
            logger.info("âœ… æ ¸å¿ƒæ¨¡å‹é¢„åŠ è½½å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹é¢„åŠ è½½å¤±è´¥: {e}")
            raise
    
    def get_model(self, model_name: str):
        """è·å–æ¨¡å‹"""
        return self.models.get(model_name)
    
    def get_pipeline(self, pipeline_name: str):
        """è·å–ç®¡é“"""
        return self.pipelines.get(pipeline_name)
    
    def get_feature_extractor(self, extractor_name: str):
        """è·å–ç‰¹å¾æå–å™¨"""
        return self.feature_extractors.get(extractor_name)
    
    def get_loaded_models(self) -> List[str]:
        """è·å–å·²åŠ è½½çš„æ¨¡å‹åˆ—è¡¨"""
        return list(self.models.keys()) + list(self.pipelines.keys())
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            "device": self.device,
            "models_count": len(self.models),
            "pipelines_count": len(self.pipelines),
            "feature_extractors_count": len(self.feature_extractors),
            "cache_dir": str(self.model_cache_dir)
        }
    
    def get_memory_usage(self) -> Dict[str, Any]:
        """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        process = psutil.Process()
        memory_info = process.memory_info()
        
        return {
            "rss": memory_info.rss / 1024 / 1024,  # MB
            "vms": memory_info.vms / 1024 / 1024,  # MB
            "percent": process.memory_percent(),
            "available": psutil.virtual_memory().available / 1024 / 1024  # MB
        }
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            logger.info("ğŸ”„ æ¸…ç†æ¨¡å‹èµ„æº...")
            
            # æ¸…ç†æ¨¡å‹
            self.models.clear()
            self.pipelines.clear()
            self.feature_extractors.clear()
            
            # æ¸…ç†GPUç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ èµ„æºæ¸…ç†å¤±è´¥: {e}")
    
    def extract_audio_features(self, audio_path: str) -> Dict[str, float]:
        """æå–éŸ³é¢‘ç‰¹å¾"""
        try:
            # åŠ è½½éŸ³é¢‘
            y, sr = librosa.load(audio_path, sr=self.feature_extractors['audio']['sample_rate'])
            
            # æå–ç‰¹å¾
            features = {}
            
            # åŸºç¡€ç‰¹å¾
            features['tempo'] = float(librosa.beat.tempo(y=y, sr=sr)[0])
            features['duration'] = float(len(y) / sr)
            
            # é¢‘è°±ç‰¹å¾
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            features['spectral_centroid_mean'] = float(np.mean(spectral_centroids))
            features['spectral_centroid_std'] = float(np.std(spectral_centroids))
            
            # MFCCç‰¹å¾
            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            for i in range(13):
                features[f'mfcc_{i}_mean'] = float(np.mean(mfccs[i]))
                features[f'mfcc_{i}_std'] = float(np.std(mfccs[i]))
            
            # è‰²åº¦ç‰¹å¾
            chroma = librosa.feature.chroma(y=y, sr=sr)
            features['chroma_mean'] = float(np.mean(chroma))
            features['chroma_std'] = float(np.std(chroma))
            
            # é›¶äº¤å‰ç‡
            zcr = librosa.feature.zero_crossing_rate(y)
            features['zcr_mean'] = float(np.mean(zcr))
            features['zcr_std'] = float(np.std(zcr))
            
            # ç®€åŒ–çš„é«˜çº§ç‰¹å¾
            features['energy'] = float(np.mean(y**2))
            features['acousticness'] = float(1.0 / (1.0 + features['spectral_centroid_mean'] / 1000))
            features['danceability'] = float(min(1.0, features['tempo'] / 180))
            features['valence'] = float(0.5 + 0.5 * np.tanh((features['tempo'] - 120) / 60))
            
            return features
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘ç‰¹å¾æå–å¤±è´¥: {e}")
            return {}
    
    def analyze_lyrics_sentiment(self, lyrics: str) -> Dict[str, Any]:
        """åˆ†ææ­Œè¯æƒ…æ„Ÿ"""
        try:
            sentiment_pipeline = self.get_pipeline('sentiment')
            if sentiment_pipeline:
                result = sentiment_pipeline(lyrics)
                return {
                    'sentiment': result[0]['label'].lower(),
                    'confidence': result[0]['score']
                }
            else:
                return {'sentiment': 'neutral', 'confidence': 0.5}
                
        except Exception as e:
            logger.error(f"æ­Œè¯æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            return {'sentiment': 'neutral', 'confidence': 0.5}